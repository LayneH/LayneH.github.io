---
title: "Learning Where to Learn in Cross-View Self-Supervised Learning"
collection: publications
permalink: /publication/2022-03-LEWEL.md
excerpt: 'New self-supervised pre-training algorithm for both image-level predictions and dense predictions.'
date: 2022-03-01
venue: 'CVPR'2022'
paperurl: 'https://arxiv.org/abs/2203.14898'
citation: 'Lang Huang, Shan You, Mingkai Zheng, Fei Wang, Chen Qian, Toshihiko Yamasaki (2022). &quot;Learning Where to Learn in Cross-View Self-Supervised Learning; <i>CVPR'2022</i>.'
---

*Abstract*: This paper aimed to address the spatial misalignment issue in current contrastive learning methods. The proposed Learning Where to Learn (LEWEL) framework adaptively performs spatial aggregation with the help of global representation, substantially improving previous contrastive methods on both image-level predictions and dense predictions.

[\[Paper\]](https://arxiv.org/abs/2203.14898) | [\[Code\]](https://github.com/LayneH/LEWEL)