---
title: "Green Hierarchical Vision Transformer for Masked Image Modeling"
collection: publications
permalink: /publication/2022-05-GreenMIM.md
excerpt: 'Efficient masked image modeling with hierarchical vision transformers.'
date: 2022-05-01
venue: 'NeurIPS'2022'
paperurl: 'https://arxiv.org/abs/2205.13515'
citation: 'Lang Huang, Shan You, Mingkai Zheng, Fei Wang, Chen Qian, Toshihiko Yamasaki (2022). &quot;Green Hierarchical Vision Transformer for Masked Image Modeling; <i>NeurIPS'2022</i>.'
---
This paper presented an efficient approach, GreenMIM, for Masked Image Modeling (MIM) with hierarchical Vision Transformers (ViTs), e.g., Swin Transformer, allowing the hierarchical ViTs to discard masked patches and operate only on the visible ones. With GreenMIM, we can train the hierarchical ViTs about 2.7 faster and reduce the GPU memory usage by 70% while still enjoying competitive performance.

[Paper](https://arxiv.org/abs/2205.13515)|[Code](https://github.com/LayneH/GreenMIM)